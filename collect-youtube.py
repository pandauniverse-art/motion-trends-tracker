import os
import json
import requests
from datetime import datetime, timedelta

# YouTube API ì„¤ì •
API_KEY = os.environ.get('YOUTUBE_API_KEY')
BASE_URL = 'https://www.googleapis.com/youtube/v3'

# ê²€ìƒ‰ í‚¤ì›Œë“œ
KEYWORDS = [
    'motion graphics 2024',
    'motion design trends',
    'after effects animation',
    'cinema 4d motion',
    'blender motion graphics',
    '3d motion design'
]

def search_youtube(keyword, max_results=10):
    """YouTubeì—ì„œ í‚¤ì›Œë“œë¡œ ë¹„ë””ì˜¤ ê²€ìƒ‰"""
    # ìµœê·¼ 30ì¼ê°„ ë¹„ë””ì˜¤ë§Œ ê²€ìƒ‰
    published_after = (datetime.now() - timedelta(days=30)).isoformat() + 'Z'
    
    params = {
        'part': 'snippet',
        'q': keyword,
        'type': 'video',
        'order': 'viewCount',
        'maxResults': max_results,
        'publishedAfter': published_after,
        'key': API_KEY
    }
    
    response = requests.get(f'{BASE_URL}/search', params=params)
    return response.json()

def get_video_stats(video_ids):
    """ë¹„ë””ì˜¤ í†µê³„ ê°€ì ¸ì˜¤ê¸°"""
    params = {
        'part': 'statistics,contentDetails',
        'id': ','.join(video_ids),
        'key': API_KEY
    }
    
    response = requests.get(f'{BASE_URL}/videos', params=params)
    return response.json()

def collect_youtube_data():
    """YouTube ë°ì´í„° ìˆ˜ì§‘ ë©”ì¸ í•¨ìˆ˜"""
    all_videos = []
    
    for keyword in KEYWORDS:
        print(f"Searching YouTube for: {keyword}")
        search_results = search_youtube(keyword)
        
        if 'items' not in search_results:
            print(f"No results for {keyword}")
            continue
        
        # ë¹„ë””ì˜¤ ID ì¶”ì¶œ
        video_ids = [item['id']['videoId'] for item in search_results['items']]
        
        # ë¹„ë””ì˜¤ í†µê³„ ê°€ì ¸ì˜¤ê¸°
        stats_data = get_video_stats(video_ids)
        
        # ë°ì´í„° ë³‘í•©
        for item, stats in zip(search_results['items'], stats_data.get('items', [])):
            video_data = {
                'platform': 'youtube',
                'id': item['id']['videoId'],
                'title': item['snippet']['title'],
                'description': item['snippet']['description'],
                'thumbnail': item['snippet']['thumbnails']['high']['url'],
                'channel': item['snippet']['channelTitle'],
                'publishedAt': item['snippet']['publishedAt'],
                'url': f"https://www.youtube.com/watch?v={item['id']['videoId']}",
                'viewCount': int(stats.get('statistics', {}).get('viewCount', 0)),
                'likeCount': int(stats.get('statistics', {}).get('likeCount', 0)),
                'commentCount': int(stats.get('statistics', {}).get('commentCount', 0)),
                'duration': stats.get('contentDetails', {}).get('duration', ''),
                'keyword': keyword,
                'collectedAt': datetime.now().isoformat()
            }
            all_videos.append(video_data)
    
    # ì¡°íšŒìˆ˜ ê¸°ì¤€ ì •ë ¬
    all_videos.sort(key=lambda x: x['viewCount'], reverse=True)
    
    # ìƒìœ„ 50ê°œë§Œ ì €ì¥
    return all_videos[:50]

if __name__ == '__main__':
    print("=== YouTube Data Collection Started ===")
    
    if not API_KEY:
        print("ERROR: YOUTUBE_API_KEY not found in environment variables")
        exit(1)
    
    videos = collect_youtube_data()
    
    # ê²°ê³¼ ì €ì¥
    output_dir = 'public/data'
    os.makedirs(output_dir, exist_ok=True)
    
    output_file = f'{output_dir}/youtube_data.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(videos, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… Collected {len(videos)} YouTube videos")
    print(f"ğŸ“ Saved to {output_file}")
